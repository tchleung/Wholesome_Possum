{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tl/anaconda3/lib/python3.7/site-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable\n",
      "/home/tl/anaconda3/lib/python3.7/site-packages/past/builtins/misc.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping\n"
     ]
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tl/anaconda3/lib/python3.7/site-packages/nltk/decorators.py:68: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly\n",
      "  regargs, varargs, varkwargs, defaults, formatvalue=lambda value: \"\"\n",
      "/home/tl/anaconda3/lib/python3.7/site-packages/nltk/lm/counter.py:15: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence, defaultdict\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "from cleaner import clean_text\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define handy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_topics(model, feature_names, no_top_words):\n",
    "    topic_dict = {}\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        topic_dict[\"Topic %d words\" % (idx)]= ['{}'.format(feature_names[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "        topic_dict[\"Topic %d weights\" % (idx)]= ['{:.1f}'.format(topic[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "    return pd.DataFrame(topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_topics2(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/all_comments_with_sentiment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prelaunch Focus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_start = '2020-03-13' #inclusive\n",
    "period_stop = '2020-03-20' #exclusive\n",
    "\n",
    "df_pre_pos = df[(df['date'] < period_stop) & (df['date'] >= period_start) & (df['sentiment'] == 'pos')]\n",
    "df_pre_neu = df[(df['date'] < period_stop) & (df['date'] >= period_start) & (df['sentiment'] == 'neu')]\n",
    "df_pre_neg = df[(df['date'] < period_stop) & (df['date'] >= period_start) & (df['sentiment'] == 'neg')]\n",
    "df_pre_pos.drop(columns=['Unnamed: 0','id','subreddit'],inplace=True)\n",
    "df_pre_neu.drop(columns=['Unnamed: 0','id','subreddit'],inplace=True)\n",
    "df_pre_neg.drop(columns=['Unnamed: 0','id','subreddit'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tl/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_pre_pos.loc[:,'cleaned'] = df_pre_pos['body'].apply(clean_text)\n",
    "df_pre_pos.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tl/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_pre_neu.loc[:,'cleaned'] = df_pre_neu['body'].apply(clean_text)\n",
    "df_pre_neu.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tl/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_pre_neg.loc[:,'cleaned'] = df_pre_neg['body'].apply(clean_text)\n",
    "df_pre_neg.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "      <th>sent_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-13 14:00:21</td>\n",
       "      <td>soundwave145</td>\n",
       "      <td>Doom,Final fantasy 7,Resident evil 3,Persona 5...</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>pos</td>\n",
       "      <td>doom final fantasy resident evil persona royal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2020-03-13 14:00:22</td>\n",
       "      <td>frescapades</td>\n",
       "      <td>Dang! Just went to pick one up and bc there wa...</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>0.2003</td>\n",
       "      <td>pos</td>\n",
       "      <td>dang went pick one bc barcode website anything...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2020-03-13 14:00:43</td>\n",
       "      <td>pearlescentsheep</td>\n",
       "      <td>SW-1421-4584-3913 â€” Probably going with Pearl...</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>0.1007</td>\n",
       "      <td>pos</td>\n",
       "      <td>probably going pearl still deciding island nam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2020-03-13 14:00:45</td>\n",
       "      <td>derekscardigan</td>\n",
       "      <td>The adding and removing insurance tip was key....</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>0.4199</td>\n",
       "      <td>pos</td>\n",
       "      <td>adding removing insurance tip key thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2020-03-13 14:00:58</td>\n",
       "      <td>AnonymousSplash</td>\n",
       "      <td>That sounds adorable! I think we have similar ...</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>0.9095</td>\n",
       "      <td>pos</td>\n",
       "      <td>sound adorable think similar mindset trying de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93720</td>\n",
       "      <td>2020-03-19 23:59:46</td>\n",
       "      <td>Smiles-Bite</td>\n",
       "      <td>It isn't great in the least. Our virus count i...</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>0.3235</td>\n",
       "      <td>pos</td>\n",
       "      <td>great least virus count skyrocketing still pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93722</td>\n",
       "      <td>2020-03-19 23:59:47</td>\n",
       "      <td>Flux85</td>\n",
       "      <td>You do realize a major part of the game in thi...</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>pos</td>\n",
       "      <td>realize major part game version resides server...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93723</td>\n",
       "      <td>2020-03-19 23:59:54</td>\n",
       "      <td>Benson2500</td>\n",
       "      <td>Of course you would. I 100% believe you lmao</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>pos</td>\n",
       "      <td>course would believe lmao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93724</td>\n",
       "      <td>2020-03-19 23:59:54</td>\n",
       "      <td>BloomyC</td>\n",
       "      <td>Really cute! I would buy from you.</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>0.5551</td>\n",
       "      <td>pos</td>\n",
       "      <td>really cute would buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93725</td>\n",
       "      <td>2020-03-19 23:59:54</td>\n",
       "      <td>cairowednesday</td>\n",
       "      <td>Thank you!</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>0.4199</td>\n",
       "      <td>pos</td>\n",
       "      <td>thank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50590 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime            author  \\\n",
       "1      2020-03-13 14:00:21      soundwave145   \n",
       "2      2020-03-13 14:00:22       frescapades   \n",
       "4      2020-03-13 14:00:43  pearlescentsheep   \n",
       "5      2020-03-13 14:00:45    derekscardigan   \n",
       "8      2020-03-13 14:00:58   AnonymousSplash   \n",
       "...                    ...               ...   \n",
       "93720  2020-03-19 23:59:46       Smiles-Bite   \n",
       "93722  2020-03-19 23:59:47            Flux85   \n",
       "93723  2020-03-19 23:59:54        Benson2500   \n",
       "93724  2020-03-19 23:59:54           BloomyC   \n",
       "93725  2020-03-19 23:59:54    cairowednesday   \n",
       "\n",
       "                                                    body        date  \\\n",
       "1      Doom,Final fantasy 7,Resident evil 3,Persona 5...  2020-03-13   \n",
       "2      Dang! Just went to pick one up and bc there wa...  2020-03-13   \n",
       "4       SW-1421-4584-3913 â€” Probably going with Pearl...  2020-03-13   \n",
       "5      The adding and removing insurance tip was key....  2020-03-13   \n",
       "8      That sounds adorable! I think we have similar ...  2020-03-13   \n",
       "...                                                  ...         ...   \n",
       "93720  It isn't great in the least. Our virus count i...  2020-03-19   \n",
       "93722  You do realize a major part of the game in thi...  2020-03-19   \n",
       "93723       Of course you would. I 100% believe you lmao  2020-03-19   \n",
       "93724                 Really cute! I would buy from you.  2020-03-19   \n",
       "93725                                         Thank you!  2020-03-19   \n",
       "\n",
       "       sent_score sentiment                                            cleaned  \n",
       "1          0.0772       pos  doom final fantasy resident evil persona royal...  \n",
       "2          0.2003       pos  dang went pick one bc barcode website anything...  \n",
       "4          0.1007       pos  probably going pearl still deciding island nam...  \n",
       "5          0.4199       pos            adding removing insurance tip key thank  \n",
       "8          0.9095       pos  sound adorable think similar mindset trying de...  \n",
       "...           ...       ...                                                ...  \n",
       "93720      0.3235       pos  great least virus count skyrocketing still pro...  \n",
       "93722      0.1154       pos  realize major part game version resides server...  \n",
       "93723      0.5994       pos                          course would believe lmao  \n",
       "93724      0.5551       pos                              really cute would buy  \n",
       "93725      0.4199       pos                                              thank  \n",
       "\n",
       "[50590 rows x 7 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the dataframes\n",
    "df_pre_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvectorizer = TfidfVectorizer(\n",
    "#     max_df = 0.99,\n",
    "#     min_df = 0.01,\n",
    "#     max_features = \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vec = tfidfvectorizer.fit_transform(df_pre_neg['cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10670, 10782)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "countvectorizer = CountVectorizer(\n",
    "#     max_df=0.95,\n",
    "#     min_df=2,\n",
    "#     max_features=n_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = countvectorizer.fit_transform(df_pre_neg['cleaned'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_topics = 10\n",
    "random_seed = 99\n",
    "ldamodel = LatentDirichletAllocation(\n",
    "    n_components=number_of_topics,\n",
    "    max_iter=50,\n",
    "    learning_method='online',\n",
    "    learning_offset=50.,\n",
    "    random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='online', learning_offset=50.0,\n",
       "                          max_doc_update_iter=100, max_iter=50,\n",
       "                          mean_change_tol=0.001, n_components=10, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=99, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.fit(count_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0 words</th>\n",
       "      <th>Topic 0 weights</th>\n",
       "      <th>Topic 1 words</th>\n",
       "      <th>Topic 1 weights</th>\n",
       "      <th>Topic 2 words</th>\n",
       "      <th>Topic 2 weights</th>\n",
       "      <th>Topic 3 words</th>\n",
       "      <th>Topic 3 weights</th>\n",
       "      <th>Topic 4 words</th>\n",
       "      <th>Topic 4 weights</th>\n",
       "      <th>Topic 5 words</th>\n",
       "      <th>Topic 5 weights</th>\n",
       "      <th>Topic 6 words</th>\n",
       "      <th>Topic 6 weights</th>\n",
       "      <th>Topic 7 words</th>\n",
       "      <th>Topic 7 weights</th>\n",
       "      <th>Topic 8 words</th>\n",
       "      <th>Topic 8 weights</th>\n",
       "      <th>Topic 9 words</th>\n",
       "      <th>Topic 9 weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>get</td>\n",
       "      <td>684.6</td>\n",
       "      <td>oh</td>\n",
       "      <td>245.5</td>\n",
       "      <td>played</td>\n",
       "      <td>140.3</td>\n",
       "      <td>im</td>\n",
       "      <td>175.4</td>\n",
       "      <td>save</td>\n",
       "      <td>73.6</td>\n",
       "      <td>digital</td>\n",
       "      <td>411.4</td>\n",
       "      <td>game</td>\n",
       "      <td>1030.8</td>\n",
       "      <td>damn</td>\n",
       "      <td>170.6</td>\n",
       "      <td>animal</td>\n",
       "      <td>494.1</td>\n",
       "      <td>die</td>\n",
       "      <td>210.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>game</td>\n",
       "      <td>655.5</td>\n",
       "      <td>hate</td>\n",
       "      <td>189.4</td>\n",
       "      <td>never</td>\n",
       "      <td>105.8</td>\n",
       "      <td>love</td>\n",
       "      <td>129.6</td>\n",
       "      <td>as</td>\n",
       "      <td>57.7</td>\n",
       "      <td>copy</td>\n",
       "      <td>389.3</td>\n",
       "      <td>one</td>\n",
       "      <td>835.4</td>\n",
       "      <td>like</td>\n",
       "      <td>104.8</td>\n",
       "      <td>crossing</td>\n",
       "      <td>450.9</td>\n",
       "      <td>sorry</td>\n",
       "      <td>180.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>itch</td>\n",
       "      <td>492.1</td>\n",
       "      <td>pick</td>\n",
       "      <td>187.3</td>\n",
       "      <td>moved</td>\n",
       "      <td>103.3</td>\n",
       "      <td>fruit</td>\n",
       "      <td>95.5</td>\n",
       "      <td>meant</td>\n",
       "      <td>50.6</td>\n",
       "      <td>physical</td>\n",
       "      <td>251.4</td>\n",
       "      <td>like</td>\n",
       "      <td>647.4</td>\n",
       "      <td>look</td>\n",
       "      <td>56.1</td>\n",
       "      <td>post</td>\n",
       "      <td>214.8</td>\n",
       "      <td>man</td>\n",
       "      <td>123.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>order</td>\n",
       "      <td>462.2</td>\n",
       "      <td>worry</td>\n",
       "      <td>104.0</td>\n",
       "      <td>villager</td>\n",
       "      <td>97.9</td>\n",
       "      <td>bob</td>\n",
       "      <td>72.6</td>\n",
       "      <td>true</td>\n",
       "      <td>50.0</td>\n",
       "      <td>two</td>\n",
       "      <td>152.0</td>\n",
       "      <td>time</td>\n",
       "      <td>636.3</td>\n",
       "      <td>cant</td>\n",
       "      <td>51.4</td>\n",
       "      <td>shit</td>\n",
       "      <td>179.3</td>\n",
       "      <td>fuck</td>\n",
       "      <td>103.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>store</td>\n",
       "      <td>447.1</td>\n",
       "      <td>dont</td>\n",
       "      <td>99.8</td>\n",
       "      <td>name</td>\n",
       "      <td>82.2</td>\n",
       "      <td>sadly</td>\n",
       "      <td>70.5</td>\n",
       "      <td>axe</td>\n",
       "      <td>43.7</td>\n",
       "      <td>bad</td>\n",
       "      <td>136.6</td>\n",
       "      <td>new</td>\n",
       "      <td>581.0</td>\n",
       "      <td>eye</td>\n",
       "      <td>50.5</td>\n",
       "      <td>doom</td>\n",
       "      <td>120.7</td>\n",
       "      <td>op</td>\n",
       "      <td>55.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>got</td>\n",
       "      <td>392.2</td>\n",
       "      <td>suck</td>\n",
       "      <td>66.0</td>\n",
       "      <td>read</td>\n",
       "      <td>80.7</td>\n",
       "      <td>lazy</td>\n",
       "      <td>67.3</td>\n",
       "      <td>japanese</td>\n",
       "      <td>40.0</td>\n",
       "      <td>want</td>\n",
       "      <td>91.0</td>\n",
       "      <td>people</td>\n",
       "      <td>561.3</td>\n",
       "      <td>color</td>\n",
       "      <td>50.2</td>\n",
       "      <td>miss</td>\n",
       "      <td>95.1</td>\n",
       "      <td>ich</td>\n",
       "      <td>37.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>day</td>\n",
       "      <td>365.9</td>\n",
       "      <td>yet</td>\n",
       "      <td>62.1</td>\n",
       "      <td>code</td>\n",
       "      <td>76.2</td>\n",
       "      <td>always</td>\n",
       "      <td>66.8</td>\n",
       "      <td>favourite</td>\n",
       "      <td>34.6</td>\n",
       "      <td>scared</td>\n",
       "      <td>79.4</td>\n",
       "      <td>get</td>\n",
       "      <td>558.9</td>\n",
       "      <td>design</td>\n",
       "      <td>49.7</td>\n",
       "      <td>see</td>\n",
       "      <td>72.6</td>\n",
       "      <td>actual</td>\n",
       "      <td>37.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>release</td>\n",
       "      <td>362.1</td>\n",
       "      <td>essential</td>\n",
       "      <td>60.5</td>\n",
       "      <td>question</td>\n",
       "      <td>66.9</td>\n",
       "      <td>sure</td>\n",
       "      <td>66.2</td>\n",
       "      <td>dizzy</td>\n",
       "      <td>34.1</td>\n",
       "      <td>problem</td>\n",
       "      <td>76.5</td>\n",
       "      <td>would</td>\n",
       "      <td>493.7</td>\n",
       "      <td>idk</td>\n",
       "      <td>47.1</td>\n",
       "      <td>please</td>\n",
       "      <td>58.0</td>\n",
       "      <td>da</td>\n",
       "      <td>34.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>still</td>\n",
       "      <td>344.9</td>\n",
       "      <td>keep</td>\n",
       "      <td>60.1</td>\n",
       "      <td>cute</td>\n",
       "      <td>57.7</td>\n",
       "      <td>hard</td>\n",
       "      <td>65.1</td>\n",
       "      <td>rock</td>\n",
       "      <td>32.5</td>\n",
       "      <td>really</td>\n",
       "      <td>71.9</td>\n",
       "      <td>know</td>\n",
       "      <td>474.5</td>\n",
       "      <td>send</td>\n",
       "      <td>46.6</td>\n",
       "      <td>information</td>\n",
       "      <td>56.0</td>\n",
       "      <td>image</td>\n",
       "      <td>33.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>mine</td>\n",
       "      <td>316.0</td>\n",
       "      <td>non</td>\n",
       "      <td>54.9</td>\n",
       "      <td>house</td>\n",
       "      <td>57.0</td>\n",
       "      <td>mad</td>\n",
       "      <td>64.1</td>\n",
       "      <td>personality</td>\n",
       "      <td>31.6</td>\n",
       "      <td>gyroids</td>\n",
       "      <td>69.0</td>\n",
       "      <td>really</td>\n",
       "      <td>469.4</td>\n",
       "      <td>bitch</td>\n",
       "      <td>46.6</td>\n",
       "      <td>removed</td>\n",
       "      <td>48.7</td>\n",
       "      <td>cherry</td>\n",
       "      <td>33.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic 0 words Topic 0 weights Topic 1 words Topic 1 weights Topic 2 words  \\\n",
       "0           get           684.6            oh           245.5        played   \n",
       "1          game           655.5          hate           189.4         never   \n",
       "2          itch           492.1          pick           187.3         moved   \n",
       "3         order           462.2         worry           104.0      villager   \n",
       "4         store           447.1          dont            99.8          name   \n",
       "5           got           392.2          suck            66.0          read   \n",
       "6           day           365.9           yet            62.1          code   \n",
       "7       release           362.1     essential            60.5      question   \n",
       "8         still           344.9          keep            60.1          cute   \n",
       "9          mine           316.0           non            54.9         house   \n",
       "\n",
       "  Topic 2 weights Topic 3 words Topic 3 weights Topic 4 words Topic 4 weights  \\\n",
       "0           140.3            im           175.4          save            73.6   \n",
       "1           105.8          love           129.6            as            57.7   \n",
       "2           103.3         fruit            95.5         meant            50.6   \n",
       "3            97.9           bob            72.6          true            50.0   \n",
       "4            82.2         sadly            70.5           axe            43.7   \n",
       "5            80.7          lazy            67.3      japanese            40.0   \n",
       "6            76.2        always            66.8     favourite            34.6   \n",
       "7            66.9          sure            66.2         dizzy            34.1   \n",
       "8            57.7          hard            65.1          rock            32.5   \n",
       "9            57.0           mad            64.1   personality            31.6   \n",
       "\n",
       "  Topic 5 words Topic 5 weights Topic 6 words Topic 6 weights Topic 7 words  \\\n",
       "0       digital           411.4          game          1030.8          damn   \n",
       "1          copy           389.3           one           835.4          like   \n",
       "2      physical           251.4          like           647.4          look   \n",
       "3           two           152.0          time           636.3          cant   \n",
       "4           bad           136.6           new           581.0           eye   \n",
       "5          want            91.0        people           561.3         color   \n",
       "6        scared            79.4           get           558.9        design   \n",
       "7       problem            76.5         would           493.7           idk   \n",
       "8        really            71.9          know           474.5          send   \n",
       "9       gyroids            69.0        really           469.4         bitch   \n",
       "\n",
       "  Topic 7 weights Topic 8 words Topic 8 weights Topic 9 words Topic 9 weights  \n",
       "0           170.6        animal           494.1           die           210.6  \n",
       "1           104.8      crossing           450.9         sorry           180.4  \n",
       "2            56.1          post           214.8           man           123.4  \n",
       "3            51.4          shit           179.3          fuck           103.5  \n",
       "4            50.5          doom           120.7            op            55.7  \n",
       "5            50.2          miss            95.1           ich            37.8  \n",
       "6            49.7           see            72.6        actual            37.8  \n",
       "7            47.1        please            58.0            da            34.1  \n",
       "8            46.6   information            56.0         image            33.9  \n",
       "9            46.6       removed            48.7        cherry            33.6  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_words = 10\n",
    "ct_feature_names = countvectorizer.get_feature_names()\n",
    "show_topics(ldamodel,ct_feature_names,top_n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tl/anaconda3/lib/python3.7/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    }
   ],
   "source": [
    "p = pyLDAvis.sklearn.prepare(ldamodel, count_vec, countvectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(p, 'lda_pre_neg.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=2000,\n",
       "    n_components=10, random_state=99, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_topics = 10\n",
    "random_seed = 99\n",
    "nmfmodel = NMF(\n",
    "    n_components=number_of_topics,\n",
    "    max_iter=2000,\n",
    "    random_state=random_seed)\n",
    "nmfmodel.fit(tf_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: get time like people really bad know want think way\n",
      "Topic #1: sorry im man hear mean suck omg right meant sold\n",
      "Topic #2: mine got th still say delayed ordered amazon yet shipped\n",
      "Topic #3: problem thank yeah enjoy bud lt see fun need make\n",
      "Topic #4: oh damn shit god yeah hell suck well hot sad\n",
      "Topic #5: game animal crossing played doom never play stop first release\n",
      "Topic #6: new sad villager leaf town horizon moved favorite first away\n",
      "Topic #7: one itch island ac name per hacked console hard know\n",
      "Topic #8: digital cancel copy order physical buy pre go get cancelled\n",
      "Topic #9: would die cry ride goldie doubt slider marshal hard pay\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_n_words = 10\n",
    "tf_feature_names = tfidfvectorizer.get_feature_names()\n",
    "show_topics2(nmfmodel,tf_feature_names,top_n_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch focus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tl/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tl/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:376: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/tl/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/home/tl/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "period_start = '2020-03-20' #inclusive\n",
    "period_stop = '2020-04-01' #exclusive\n",
    "\n",
    "df_launch = df[(df['date'] < period_stop) & (df['date'] >= period_start)]\n",
    "df_launch.drop(columns=['Unnamed: 0','id','subreddit'],inplace=True)\n",
    "\n",
    "df_launch.loc[:,'cleaned'] = df_launch['body'].apply(clean_text)\n",
    "df_launch.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_launch.to_csv('../data/launch_cleaned_all_sentiment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting NMF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvectorizer_launch = TfidfVectorizer(\n",
    "#     max_df = 0.99,\n",
    "#     min_df = 0.01,\n",
    "#     max_features = \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238242, 43316)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_focus = 'pos'\n",
    "filtered_frame = df_launch[df_launch['sentiment'] == sentiment_focus]['cleaned']\n",
    "\n",
    "tf_vec_launch = tfidfvectorizer_launch.fit_transform(filtered_frame)\n",
    "tf_vec_launch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=2000,\n",
       "    n_components=10, random_state=99, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_topics = 10\n",
    "random_seed = 99\n",
    "nmfmodel_launch = NMF(\n",
    "    n_components=number_of_topics,\n",
    "    max_iter=2000,\n",
    "    random_state=random_seed)\n",
    "nmfmodel_launch.fit(tf_vec_launch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: thank much awesome oh okay ok ah great amazing know\n",
      "Topic #1: code dodo please looking fruit dm peach orange cherry apple\n",
      "Topic #2: thanks ok much awesome oh okay cool know info ah\n",
      "Topic #3: yes please omg move day believe ah one unfortunately oh\n",
      "Topic #4: like island get one game time day villager know want\n",
      "Topic #5: love would much visit omg come amazing see great design\n",
      "Topic #6: lol oh yeah got ok mine omg thought know need\n",
      "Topic #7: nice look oh really job would wow great work good\n",
      "Topic #8: friend code request sent add play best send new itch\n",
      "Topic #9: cute awesome super omg look really oh great idea job\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_n_words = 10\n",
    "tf_feature_names_launch = tfidfvectorizer_launch.get_feature_names()\n",
    "show_topics2(nmfmodel_launch,tf_feature_names_launch,top_n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163143, 30733)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_focus = 'neu'\n",
    "filtered_frame = df_launch[df_launch['sentiment'] == sentiment_focus]['cleaned']\n",
    "\n",
    "tf_vec_launch = tfidfvectorizer_launch.fit_transform(filtered_frame)\n",
    "tf_vec_launch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=2000,\n",
       "    n_components=10, random_state=99, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_topics = 10\n",
    "random_seed = 99\n",
    "nmfmodel_launch = NMF(\n",
    "    n_components=number_of_topics,\n",
    "    max_iter=2000,\n",
    "    random_state=random_seed)\n",
    "nmfmodel_launch.fit(tf_vec_launch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: code dodo dm qr pm send looking open new hemisphere\n",
      "Topic #1: island come fruit open visit nook hemisphere fish southern mile\n",
      "Topic #2: added open gate name back pop ya bring hi add\n",
      "Topic #3: cherry peach pear apple orange trade bring looking coconut fruit\n",
      "Topic #4: get recipe nook mile able game villager house trying ladder\n",
      "Topic #5: got today mine pear balloon recipe one first yesterday iron\n",
      "Topic #6: way make know game go think find headed work bringing\n",
      "Topic #7: day one remindme time think next first villager new game\n",
      "Topic #8: sent request dm pm message chat amp link check downloadable\n",
      "Topic #9: need still fruit iron know open anything omg shop space\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_n_words = 10\n",
    "tf_feature_names_launch = tfidfvectorizer_launch.get_feature_names()\n",
    "show_topics2(nmfmodel_launch,tf_feature_names_launch,top_n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73427, 23125)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_focus = 'neg'\n",
    "filtered_frame = df_launch[df_launch['sentiment'] == sentiment_focus]['cleaned']\n",
    "\n",
    "tf_vec_launch = tfidfvectorizer_launch.fit_transform(filtered_frame)\n",
    "tf_vec_launch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=2000,\n",
       "    n_components=10, random_state=99, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_topics = 10\n",
    "random_seed = 99\n",
    "nmfmodel_launch = NMF(\n",
    "    n_components=number_of_topics,\n",
    "    max_iter=2000,\n",
    "    random_state=random_seed)\n",
    "nmfmodel_launch.fit(tf_vec_launch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: time game like people think day thing get really know travel way would play sure make animal even back wrong\n",
      "Topic #1: sorry loss know sure im new closed mean hear internet yet guy gate meant full people post ah connection question\n",
      "Topic #2: problem lol know fun else exact anyone yeah see fix haha thanks work let thank hope well glad fixed sound\n",
      "Topic #3: island tarantula mystery nook mile fruit ticket native bamboo flower visit spawn full go rock fish found find itch different\n",
      "Topic #4: tree get axe fruit rock shake shovel hit stone flimsy cut use wood iron grow break shaking chop need eat\n",
      "Topic #5: bad want feel luck lol really like go make bot need good thanks look got turnip thing man omg right\n",
      "Topic #6: oh damn shit god fuck know thanks thank hell suck man yeah well really holy thought idea wait full crap\n",
      "Topic #7: code dodo drop need peach cherry orange apple fruit pear dm ill come looking interference pay open bell pm bring\n",
      "Topic #8: one got day caught first fish per catch bait two sure another today yet found itch last river new stringfish\n",
      "Topic #9: villager move first house get plot campsite leave nook invite day new talk want random town unfortunately empty tom build\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_n_words = 20\n",
    "tf_feature_names_launch = tfidfvectorizer_launch.get_feature_names()\n",
    "show_topics2(nmfmodel_launch,tf_feature_names_launch,top_n_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bunny day focus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tl/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tl/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:376: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/tl/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/home/tl/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "period_start = '2020-04-01' #inclusive\n",
    "period_stop = '2020-04-13' #exclusive\n",
    "\n",
    "df_bunny = df[(df['date'] < period_stop) & (df['date'] >= period_start)]\n",
    "df_bunny.drop(columns=['Unnamed: 0','id','subreddit'],inplace=True)\n",
    "\n",
    "df_bunny.loc[:,'cleaned'] = df_bunny['body'].apply(clean_text)\n",
    "df_bunny.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bunny.to_csv('../data/bunny_cleaned_all_sentiment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF - Bunny day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bunny = pd.read_csv('../data/bunny_cleaned_all_sentiment.csv')\n",
    "# df_bunny.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvectorizer_bunny = TfidfVectorizer(\n",
    "#     max_df = 0.99,\n",
    "#     min_df = 0.01,\n",
    "#     max_features = \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bunny day - positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242444, 39987)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_focus = 'pos'\n",
    "filtered_frame = df_bunny[df_bunny['sentiment'] == sentiment_focus]['cleaned']\n",
    "\n",
    "tf_vec_bunny = tfidfvectorizer_bunny.fit_transform(filtered_frame)\n",
    "tf_vec_bunny.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=2000,\n",
       "    n_components=10, random_state=99, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_topics = 10\n",
    "random_seed = 99\n",
    "nmfmodel_bunny = NMF(\n",
    "    n_components=number_of_topics,\n",
    "    max_iter=2000,\n",
    "    random_state=random_seed)\n",
    "nmfmodel_bunny.fit(tf_vec_bunny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: thank much oh okay ok awesome ah lt god omg\n",
      "Topic #1: like one get island day villager time game want make\n",
      "Topic #2: thanks ok much oh okay awesome info cool ah know\n",
      "Topic #3: yes please omg move oh message ah need plot one\n",
      "Topic #4: love would much omg come visit amazing idea absolutely see\n",
      "Topic #5: code dm please dodo looking fruit friend island open shop\n",
      "Topic #6: good awesome know look oh luck great idea amazing price\n",
      "Topic #7: lol oh yeah got thought ok right need mine okay\n",
      "Topic #8: cute omg super look really idea great little dress aww\n",
      "Topic #9: nice look really oh would job wow great cool work\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_n_words = 10\n",
    "tf_feature_names_bunny = tfidfvectorizer_bunny.get_feature_names()\n",
    "show_topics2(nmfmodel_bunny,tf_feature_names_bunny,top_n_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bunny day - neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151479, 27319)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_focus = 'neu'\n",
    "filtered_frame = df_bunny[df_bunny['sentiment'] == sentiment_focus]['cleaned']\n",
    "\n",
    "tf_vec_bunny = tfidfvectorizer_bunny.fit_transform(filtered_frame)\n",
    "tf_vec_bunny.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=2000,\n",
       "    n_components=10, random_state=99, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_topics = 10\n",
    "random_seed = 99\n",
    "nmfmodel_bunny = NMF(\n",
    "    n_components=number_of_topics,\n",
    "    max_iter=2000,\n",
    "    random_state=random_seed)\n",
    "nmfmodel_bunny.fit(tf_vec_bunny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: cherry recipe blossom diy looking trade give peach anyone pear\n",
      "Topic #1: dm sent looking check turnip ed dodo price selling anyone\n",
      "Topic #2: code dodo send qr creator bring give open shop new\n",
      "Topic #3: get recipe villager star way trying rid wait able know\n",
      "Topic #4: island come nook villager sell visit fruit go open looking\n",
      "Topic #5: one make villager first think new give move could per\n",
      "Topic #6: need still fruit many orange craft flower open know pear\n",
      "Topic #7: day bunny time egg think next first every th remindme\n",
      "Topic #8: pm sent message request chat amp link time ed downloadable\n",
      "Topic #9: got today balloon mine think yesterday first star red orange\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_n_words = 10\n",
    "tf_feature_names_bunny = tfidfvectorizer_bunny.get_feature_names()\n",
    "show_topics2(nmfmodel_bunny,tf_feature_names_bunny,top_n_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bunny day - negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79619, 23940)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_focus = 'neg'\n",
    "filtered_frame = df_bunny[df_bunny['sentiment'] == sentiment_focus]['cleaned']\n",
    "\n",
    "tf_vec_bunny = tfidfvectorizer_bunny.fit_transform(filtered_frame)\n",
    "tf_vec_bunny.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=2000,\n",
       "    n_components=10, random_state=99, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_topics = 10\n",
    "random_seed = 99\n",
    "nmfmodel_bunny = NMF(\n",
    "    n_components=number_of_topics,\n",
    "    max_iter=2000,\n",
    "    random_state=random_seed)\n",
    "nmfmodel_bunny.fit(tf_vec_bunny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: time one get game like people know think sure would thing really day way back even make could go wrong\n",
      "Topic #1: recipe cherry blossom balloon day bunny got diy get missing event drop gotten still sakura petal item tree anyone one\n",
      "Topic #2: problem yeah got code thanks thank fix solution see opposite else okay dm sure lol modern online solved dodo anyone\n",
      "Topic #3: sorry loss code im know new already ah someone hear closed idea got mean question late dodo post open meant\n",
      "Topic #4: villager move plot campsite day first empty leave invite house random someone one amiibo talk camper new moved want moving\n",
      "Topic #5: island tarantula fruit tree bug spawn mystery nook bamboo flower rock mile sell water code come drop flick visit native\n",
      "Topic #6: bad want feel really luck lol badly make dont go right leave anyone bot ugh ah people know thing jealous\n",
      "Topic #7: egg fish water hate bait fishing damn bunny event catch getting wood annoying sky spawn day balloon bug rock get\n",
      "Topic #8: oh damn shit fuck god thank thanks suck know man thought well yeah hell lol hate really right holy guess\n",
      "Topic #9: board cutting need dresser make ironwood trade kitchenette pay dm diy anyone bell looking code craft recipe give iron willing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_n_words = 20\n",
    "tf_feature_names_bunny = tfidfvectorizer_bunny.get_feature_names()\n",
    "show_topics2(nmfmodel_bunny,tf_feature_names_bunny,top_n_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Bunny-day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tl/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "period_start = '2020-04-13' #inclusive\n",
    "period_stop = '2020-04-23' #exclusive\n",
    "\n",
    "df_postbunny = df[(df['date'] < period_stop) & (df['date'] >= period_start)]\n",
    "df_postbunny.drop(columns=['Unnamed: 0','id','subreddit'],inplace=True)\n",
    "\n",
    "df_postbunny.loc[:,'cleaned'] = df_postbunny['body'].apply(clean_text)\n",
    "df_postbunny.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvectorizer_postbunny = TfidfVectorizer(\n",
    "#     max_df = 0.99,\n",
    "#     min_df = 0.01,\n",
    "#     max_features = \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-bunny - positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203880, 36267)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_focus = 'pos'\n",
    "filtered_frame = df_postbunny[df_postbunny['sentiment'] == sentiment_focus]['cleaned']\n",
    "\n",
    "tf_vec_postbunny = tfidfvectorizer_postbunny.fit_transform(filtered_frame)\n",
    "tf_vec_postbunny.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=2000,\n",
       "    n_components=10, random_state=99, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_topics = 10\n",
    "random_seed = 99\n",
    "nmfmodel_postbunny = NMF(\n",
    "    n_components=number_of_topics,\n",
    "    max_iter=2000,\n",
    "    random_state=random_seed)\n",
    "nmfmodel_postbunny.fit(tf_vec_postbunny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: thank much awesome oh okay ok know omg lt great\n",
      "Topic #1: island one get villager want day time game know make\n",
      "Topic #2: thanks ok much oh okay awesome know info cool help\n",
      "Topic #3: love would come much visit omg idea see absolutely wow\n",
      "Topic #4: yes please omg ah move oh pls say random course\n",
      "Topic #5: dm code please dodo looking come shop tip anyone visit\n",
      "Topic #6: nice really look oh job work wow haha good cool\n",
      "Topic #7: cute super omg idea look really oh aww great wow\n",
      "Topic #8: lol oh ok yeah thought got omg know mine made\n",
      "Topic #9: like would look amazing awesome great really visit come feel\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_n_words = 10\n",
    "tf_feature_names_postbunny = tfidfvectorizer_postbunny.get_feature_names()\n",
    "show_topics2(nmfmodel_postbunny,tf_feature_names_postbunny,top_n_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-bunny - neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119272, 25588)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_focus = 'neu'\n",
    "filtered_frame = df_postbunny[df_postbunny['sentiment'] == sentiment_focus]['cleaned']\n",
    "\n",
    "tf_vec_postbunny = tfidfvectorizer_postbunny.fit_transform(filtered_frame)\n",
    "tf_vec_postbunny.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=2000,\n",
       "    n_components=10, random_state=99, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_topics = 10\n",
    "random_seed = 99\n",
    "nmfmodel_postbunny = NMF(\n",
    "    n_components=number_of_topics,\n",
    "    max_iter=2000,\n",
    "    random_state=random_seed)\n",
    "nmfmodel_postbunny.fit(tf_vec_postbunny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: dm ed dodo sent check hi offer sending send looking\n",
      "Topic #1: island visit sell mystery flick fruit open celeste fish tarantula\n",
      "Topic #2: code dodo qr pm send posted bring creator give new\n",
      "Topic #3: come visit hi may could mine buy wanna hey back\n",
      "Topic #4: get recipe rid trying star diy way flower could tree\n",
      "Topic #5: sent chat pm message request gt msg send working private\n",
      "Topic #6: one make craft give per recipe catalog first could blue\n",
      "Topic #7: looking shop rose anyone red nook seed white yellow cosmos\n",
      "Topic #8: need still fruit many cherry omg make apple tree pear\n",
      "Topic #9: day villager time got think know move game house go\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_n_words = 10\n",
    "tf_feature_names_postbunny = tfidfvectorizer_postbunny.get_feature_names()\n",
    "show_topics2(nmfmodel_postbunny,tf_feature_names_postbunny,top_n_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-bunny - Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62366, 21969)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_focus = 'neg'\n",
    "filtered_frame = df_postbunny[df_postbunny['sentiment'] == sentiment_focus]['cleaned']\n",
    "\n",
    "tf_vec_postbunny = tfidfvectorizer_postbunny.fit_transform(filtered_frame)\n",
    "tf_vec_postbunny.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=2000,\n",
       "    n_components=10, random_state=99, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_topics = 10\n",
    "random_seed = 99\n",
    "nmfmodel_postbunny = NMF(\n",
    "    n_components=number_of_topics,\n",
    "    max_iter=2000,\n",
    "    random_state=random_seed)\n",
    "nmfmodel_postbunny.fit(tf_vec_postbunny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: get time game like people think know would thing really day make way even hate\n",
      "Topic #1: sorry loss know new im hear already late got still code meant someone happened ah\n",
      "Topic #2: cutting board dresser recipe ironwood diy need make kitchenette craft got iron still table looking\n",
      "Topic #3: problem thank yeah sure see code thanks well glad else opposite dodo fix think much\n",
      "Topic #4: villager move plot empty leave house campsite day random ask invite someone talk amiibo moving\n",
      "Topic #5: island unfortunately tarantula sell flick mystery spawn bug visit fruit flower go tree rock come\n",
      "Topic #6: bad want feel make lol really luck badly ah look omg give felt need thank\n",
      "Topic #7: one day got first bunny two per every another recipe next sure missing find take\n",
      "Topic #8: oh damn shit know god fuck suck thanks really well man hell yeah thank thought\n",
      "Topic #9: pay dm code bell dodo looking anyone drop nook need ill shop tip come fruit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_n_words = 15\n",
    "tf_feature_names_postbunny = tfidfvectorizer_postbunny.get_feature_names()\n",
    "show_topics2(nmfmodel_postbunny,tf_feature_names_postbunny,top_n_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spring update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tl/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/home/tl/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:376: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/tl/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/home/tl/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "period_start = '2020-04-23' #inclusive\n",
    "period_stop = '2020-05-01' #exclusive\n",
    "\n",
    "df_spring = df[(df['date'] < period_stop) & (df['date'] >= period_start)]\n",
    "df_spring.drop(columns=['Unnamed: 0','id','subreddit'],inplace=True)\n",
    "\n",
    "df_spring.loc[:,'cleaned'] = df_spring['body'].apply(clean_text)\n",
    "df_spring.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvectorizer_spring = TfidfVectorizer(\n",
    "#     max_df = 0.99,\n",
    "#     min_df = 0.01,\n",
    "#     max_features = \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spring - positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169581, 33193)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_focus = 'pos'\n",
    "filtered_frame = df_spring[df_spring['sentiment'] == sentiment_focus]['cleaned']\n",
    "\n",
    "tf_vec_spring = tfidfvectorizer_spring.fit_transform(filtered_frame)\n",
    "tf_vec_spring.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=2000,\n",
       "    n_components=10, random_state=99, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_topics = 10\n",
    "random_seed = 99\n",
    "nmfmodel_spring = NMF(\n",
    "    n_components=number_of_topics,\n",
    "    max_iter=2000,\n",
    "    random_state=random_seed)\n",
    "nmfmodel_spring.fit(tf_vec_spring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: thank much okay oh awesome ok ah lt great know\n",
      "Topic #1: island one villager want get day time game know make\n",
      "Topic #2: thanks ok much oh awesome know okay cool sharing info\n",
      "Topic #3: love would come visit much omg idea see wow id\n",
      "Topic #4: yes please omg oh say random pls move ah day\n",
      "Topic #5: dm please code dodo come interested looking tip anyone visit\n",
      "Topic #6: nice look really oh job work wow good idea cool\n",
      "Topic #7: cute super omg really idea look great villager oh think\n",
      "Topic #8: like look would great amazing awesome come really cool visit\n",
      "Topic #9: lol oh yeah omg know thought got mine good okay\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_n_words = 10\n",
    "tf_feature_names_spring = tfidfvectorizer_spring.get_feature_names()\n",
    "show_topics2(nmfmodel_spring,tf_feature_names_spring,top_n_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spring - Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98116, 22454)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_focus = 'neu'\n",
    "filtered_frame = df_spring[df_spring['sentiment'] == sentiment_focus]['cleaned']\n",
    "\n",
    "tf_vec_spring = tfidfvectorizer_spring.fit_transform(filtered_frame)\n",
    "tf_vec_spring.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=2000,\n",
       "    n_components=10, random_state=99, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_topics = 10\n",
    "random_seed = 99\n",
    "nmfmodel_spring = NMF(\n",
    "    n_components=number_of_topics,\n",
    "    max_iter=2000,\n",
    "    random_state=random_seed)\n",
    "nmfmodel_spring.fit(tf_vec_spring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: dm ed dodo offer sent nmt check selling let sending\n",
      "Topic #1: island visit sell mystery redd flick open someone fruit go\n",
      "Topic #2: come visit may could hi mine wanna hey let sell\n",
      "Topic #3: code dodo send pm creator message qr open design give\n",
      "Topic #4: sent chat message pm request msg send hi working via\n",
      "Topic #5: one make got give craft could real per buy find\n",
      "Topic #6: get rid trying recipe star could diy way nook hedge\n",
      "Topic #7: need still many fruit flower open orange cherry pear tree\n",
      "Topic #8: day villager time think move first game know wait random\n",
      "Topic #9: anyone looking got nook buy diy box shop selling bell\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_n_words = 10\n",
    "tf_feature_names_spring = tfidfvectorizer_spring.get_feature_names()\n",
    "show_topics2(nmfmodel_spring,tf_feature_names_spring,top_n_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spring - negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51108, 20491)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_focus = 'neg'\n",
    "filtered_frame = df_spring[df_spring['sentiment'] == sentiment_focus]['cleaned']\n",
    "\n",
    "tf_vec_spring = tfidfvectorizer_spring.fit_transform(filtered_frame)\n",
    "tf_vec_spring.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=2000,\n",
       "    n_components=10, random_state=99, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_topics = 10\n",
    "random_seed = 99\n",
    "nmfmodel_spring = NMF(\n",
    "    n_components=number_of_topics,\n",
    "    max_iter=2000,\n",
    "    random_state=random_seed)\n",
    "nmfmodel_spring.fit(tf_vec_spring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: time get game like people day think would know really\n",
      "Topic #1: sorry loss someone hear already happened im sure code know\n",
      "Topic #2: fake real painting art redd statue buy sell today tell\n",
      "Topic #3: problem yeah thank right code haha see issue solution thanks\n",
      "Topic #4: villager plot move empty leave day house campsite need random\n",
      "Topic #5: island unfortunately mystery visit come sell someone flick tarantula fruit\n",
      "Topic #6: pay board cutting dm bell looking diy anyone need code\n",
      "Topic #7: bad want feel luck really lol dont badly man make\n",
      "Topic #8: oh damn shit fuck god know suck thanks thank man\n",
      "Topic #9: one day real take leave per got first two buy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_n_words = 10\n",
    "tf_feature_names_spring = tfidfvectorizer_spring.get_feature_names()\n",
    "show_topics2(nmfmodel_spring,tf_feature_names_spring,top_n_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post May-day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tl/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/home/tl/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:376: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/tl/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/home/tl/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "period_start = '2020-05-01' #inclusive\n",
    "period_stop = '2020-05-09' #exclusive\n",
    "\n",
    "df_may = df[(df['date'] < period_stop) & (df['date'] >= period_start)]\n",
    "df_may.drop(columns=['Unnamed: 0','id','subreddit'],inplace=True)\n",
    "\n",
    "df_may.loc[:,'cleaned'] = df_may['body'].apply(clean_text)\n",
    "df_may.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvectorizer_may = TfidfVectorizer(\n",
    "#     max_df = 0.99,\n",
    "#     min_df = 0.01,\n",
    "#     max_features = \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post May-day - Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149829, 31137)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_focus = 'pos'\n",
    "filtered_frame = df_may[df_may['sentiment'] == sentiment_focus]['cleaned']\n",
    "\n",
    "tf_vec_may = tfidfvectorizer_may.fit_transform(filtered_frame)\n",
    "tf_vec_may.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=2000,\n",
       "    n_components=10, random_state=99, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_topics = 10\n",
    "random_seed = 99\n",
    "nmfmodel_may = NMF(\n",
    "    n_components=number_of_topics,\n",
    "    max_iter=2000,\n",
    "    random_state=random_seed)\n",
    "nmfmodel_may.fit(tf_vec_may)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: thank much oh ok okay know lt awesome ah helpful\n",
      "Topic #1: like island one villager get want game time day would\n",
      "Topic #2: thanks much ok oh know okay awesome ah cool info\n",
      "Topic #3: love would come much visit omg see idea absolutely hi\n",
      "Topic #4: yes please omg oh ah move haha say day random\n",
      "Topic #5: dm please code dodo interested looking anyone come flower tip\n",
      "Topic #6: cute super omg idea really villager look aww think little\n",
      "Topic #7: nice really job look work oh would super wow haha\n",
      "Topic #8: lol oh ok yeah know thought got omg made mine\n",
      "Topic #9: amazing look awesome great good wow job cool idea oh\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_n_words = 10\n",
    "tf_feature_names_may = tfidfvectorizer_may.get_feature_names()\n",
    "show_topics2(nmfmodel_may,tf_feature_names_may,top_n_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post may-day - neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82711, 20469)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_focus = 'neu'\n",
    "filtered_frame = df_may[df_may['sentiment'] == sentiment_focus]['cleaned']\n",
    "\n",
    "tf_vec_may = tfidfvectorizer_may.fit_transform(filtered_frame)\n",
    "tf_vec_may.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=2000,\n",
       "    n_components=10, random_state=99, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_topics = 10\n",
    "random_seed = 99\n",
    "nmfmodel_may = NMF(\n",
    "    n_components=number_of_topics,\n",
    "    max_iter=2000,\n",
    "    random_state=random_seed)\n",
    "nmfmodel_may.fit(tf_vec_may)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: dm dodo offer selling nmt sent working ed hi nmts\n",
      "Topic #1: island visit sell redd open mystery star fruit flick celeste\n",
      "Topic #2: come visit may could water hi mine wanna hey shop\n",
      "Topic #3: one make craft got per day catalog white find blue\n",
      "Topic #4: code dodo send pm creator open design message qr shop\n",
      "Topic #5: sent chat message pm request sending msg send check via\n",
      "Topic #6: get rid trying recipe star diy item fruit many could\n",
      "Topic #7: looking anyone buy diy tip bell nmt box flower selling\n",
      "Topic #8: need still many fruit flower open water bell orange know\n",
      "Topic #9: villager time day got know think move first game go\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_n_words = 10\n",
    "tf_feature_names_may = tfidfvectorizer_may.get_feature_names()\n",
    "show_topics2(nmfmodel_may,tf_feature_names_may,top_n_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post may-day - negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42790, 19238)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_focus = 'neg'\n",
    "filtered_frame = df_may[df_may['sentiment'] == sentiment_focus]['cleaned']\n",
    "\n",
    "tf_vec_may = tfidfvectorizer_may.fit_transform(filtered_frame)\n",
    "tf_vec_may.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=2000,\n",
       "    n_components=10, random_state=99, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_topics = 10\n",
    "random_seed = 99\n",
    "nmfmodel_may = NMF(\n",
    "    n_components=number_of_topics,\n",
    "    max_iter=2000,\n",
    "    random_state=random_seed)\n",
    "nmfmodel_may.fit(tf_vec_may)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: get time like game people know think really would make\n",
      "Topic #1: sorry already im someone know got happened code hear loss\n",
      "Topic #2: pay dm bell looking diy anyone dodo code flower need\n",
      "Topic #3: problem know thanks tree yeah let solution thank friend reply\n",
      "Topic #4: fake redd painting real art statue buy selling looking buying\n",
      "Topic #5: villager plot empty move leave day campsite random house box\n",
      "Topic #6: island unfortunately come mystery visit sell star spawn flick tree\n",
      "Topic #7: bad want feel dont luck lol make badly anyone really\n",
      "Topic #8: one day leave got take first per two yet rock\n",
      "Topic #9: oh damn shit fuck god suck thanks thank know hell\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_n_words = 10\n",
    "tf_feature_names_may = tfidfvectorizer_may.get_feature_names()\n",
    "show_topics2(nmfmodel_may,tf_feature_names_may,top_n_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Topic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "all_cleaned = df['body'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cleaned.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "countvectorizer = CountVectorizer(\n",
    "#     max_df=0.95,\n",
    "#     min_df=2,\n",
    "#     max_features=n_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = countvectorizer.fit_transform(all_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_topics = 10\n",
    "random_seed = 99\n",
    "ldamodel = LatentDirichletAllocation(\n",
    "    n_components=number_of_topics,\n",
    "    max_iter=50,\n",
    "    learning_method='online',\n",
    "    learning_offset=50.,\n",
    "    random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel.fit(count_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_words = 10\n",
    "ct_feature_names = countvectorizer.get_feature_names()\n",
    "show_topics(ldamodel,ct_feature_names,top_n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_all = pyLDAvis.sklearn.prepare(ldamodel, count_vec, countvectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(page, 'lda_all.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
